{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {(18, 10, 0): -0.5970149253731343, (15, 10, 0): -0.6535433070866141, (11, 10, 0): -0.45962732919254656, (20, 5, 1): 0.047619047619047616, (19, 5, 0): -0.2765957446808511, (16, 5, 0): -0.43373493975903615, (18, 5, 0): -0.4166666666666667, (17, 5, 1): -0.14285714285714285, (21, 5, 1): 0.5882352941176471, (18, 3, 0): -0.5151515151515151, (20, 10, 0): -0.34536082474226804, (19, 10, 0): -0.4, (14, 10, 0): -0.6360424028268551, (16, 8, 0): -0.4918032786885246, (20, 6, 0): -0.020618556701030927, (15, 9, 0): -0.509090909090909, (8, 8, 0): -0.3888888888888889, (17, 5, 0): -0.31666666666666665, (8, 4, 0): -0.20833333333333334, (16, 3, 0): -0.4810126582278481, (13, 3, 0): -0.41975308641975306, (13, 9, 0): -0.581081081081081, (12, 10, 0): -0.5918367346938775, (18, 9, 0): -0.3728813559322034, (9, 10, 0): -0.6410256410256411, (21, 10, 1): 0.13917525773195877, (13, 10, 1): -0.546875, (13, 10, 0): -0.7230215827338129, (14, 4, 0): -0.3880597014925373, (16, 9, 0): -0.6125, (10, 10, 0): -0.631578947368421, (18, 1, 0): -0.6756756756756757, (18, 6, 1): 0.3125, (17, 6, 0): -0.36923076923076925, (16, 10, 0): -0.7098976109215017, (17, 10, 0): -0.6363636363636364, (6, 9, 0): -0.6428571428571429, (18, 2, 0): -0.2, (20, 3, 0): -0.125, (16, 7, 0): -0.6875, (20, 9, 1): 0.09090909090909091, (19, 9, 0): -0.125, (18, 4, 0): -0.4827586206896552, (19, 2, 0): -0.22916666666666666, (9, 2, 0): -0.4838709677419355, (11, 2, 0): -0.4, (20, 7, 1): 0.28, (12, 7, 0): -0.4939759036144578, (15, 5, 0): -0.4, (20, 4, 0): -0.04081632653061224, (17, 4, 0): -0.55, (12, 5, 0): -0.4626865671641791, (20, 1, 0): -0.4895833333333333, (15, 2, 0): -0.5538461538461539, (19, 7, 0): 0.09230769230769231, (17, 7, 0): -0.5098039215686274, (21, 10, 0): -0.04424778761061947, (15, 7, 0): -0.4117647058823529, (19, 4, 0): -0.20967741935483872, (21, 4, 1): 0.34146341463414637, (20, 4, 1): 0.3333333333333333, (12, 2, 0): -0.2553191489361702, (19, 3, 0): -0.2638888888888889, (12, 3, 0): -0.24615384615384617, (13, 8, 0): -0.4444444444444444, (17, 10, 1): -0.647887323943662, (15, 10, 1): -0.6842105263157895, (17, 3, 0): -0.27586206896551724, (21, 1, 0): -0.16129032258064516, (13, 1, 0): -0.8271604938271605, (20, 5, 0): -0.18584070796460178, (10, 1, 0): -0.5853658536585366, (15, 4, 0): -0.32727272727272727, (20, 2, 0): -0.21839080459770116, (11, 1, 0): -0.5238095238095238, (13, 5, 0): -0.5068493150684932, (10, 5, 0): -0.027777777777777776, (17, 4, 1): -0.058823529411764705, (20, 9, 0): -0.23711340206185566, (14, 2, 0): -0.3783783783783784, (13, 7, 0): -0.4230769230769231, (9, 7, 0): -0.4, (15, 8, 0): -0.6233766233766234, (13, 2, 1): -0.36363636363636365, (17, 2, 0): -0.5636363636363636, (7, 2, 0): -0.75, (15, 6, 0): -0.5068493150684932, (6, 6, 0): -0.047619047619047616, (20, 7, 0): -0.11428571428571428, (14, 3, 0): -0.625, (13, 6, 0): -0.4745762711864407, (8, 6, 0): -0.07142857142857142, (18, 8, 1): -0.26666666666666666, (17, 8, 1): -0.2692307692307692, (6, 5, 0): -0.3333333333333333, (17, 8, 0): -0.5342465753424658, (15, 7, 1): -0.7272727272727273, (11, 9, 0): -0.48717948717948717, (8, 9, 0): -0.68, (14, 1, 0): -0.782051282051282, (9, 9, 0): -0.36666666666666664, (11, 4, 0): -0.4473684210526316, (21, 3, 0): 0.03333333333333333, (11, 3, 0): -0.35135135135135137, (8, 3, 0): -0.5555555555555556, (14, 8, 0): -0.6811594202898551, (14, 8, 1): -0.38461538461538464, (5, 8, 0): -0.5, (19, 9, 1): -0.1935483870967742, (21, 9, 1): 0.2826086956521739, (17, 9, 0): -0.5555555555555556, (20, 3, 1): -0.391304347826087, (15, 3, 1): -0.35714285714285715, (13, 3, 1): 0.0, (14, 3, 1): -0.18181818181818182, (17, 9, 1): -0.42857142857142855, (20, 2, 1): 0.3333333333333333, (17, 2, 1): 0.2, (11, 8, 0): -0.375, (10, 7, 0): -0.5333333333333333, (6, 4, 0): -0.7692307692307693, (7, 7, 0): -0.6190476190476191, (18, 6, 0): -0.05, (16, 4, 0): -0.5483870967741935, (13, 7, 1): -0.5, (10, 2, 0): -0.15625, (9, 4, 0): -0.3225806451612903, (9, 8, 0): -0.6666666666666666, (12, 9, 0): -0.4675324675324675, (14, 7, 0): -0.4827586206896552, (4, 3, 0): -0.3333333333333333, (8, 10, 0): -0.5340909090909091, (15, 5, 1): 0.13333333333333333, (14, 5, 0): -0.3, (17, 1, 0): -0.7, (16, 2, 0): -0.47058823529411764, (15, 4, 1): -0.7333333333333333, (11, 6, 0): -0.19444444444444445, (9, 6, 0): -0.04, (12, 6, 0): -0.3048780487804878, (7, 10, 0): -0.47619047619047616, (20, 8, 0): -0.14285714285714285, (19, 1, 0): -0.40384615384615385, (9, 1, 0): -0.48484848484848486, (18, 8, 0): -0.4107142857142857, (21, 8, 1): 0.18181818181818182, (20, 10, 1): -0.16216216216216217, (7, 5, 0): 0.0, (18, 7, 0): -0.21311475409836064, (5, 10, 0): -0.5897435897435898, (13, 4, 0): -0.4024390243902439, (19, 10, 1): -0.37681159420289856, (17, 3, 1): -0.23333333333333334, (19, 2, 1): 0.10526315789473684, (12, 2, 1): -0.25, (16, 10, 1): -0.5405405405405406, (15, 3, 0): -0.463768115942029, (15, 1, 0): -0.691358024691358, (11, 5, 0): 0.16, (17, 7, 1): -0.4375, (14, 9, 0): -0.7192982456140351, (16, 1, 0): -0.8307692307692308, (12, 1, 0): -0.7126436781609196, (10, 8, 0): -0.24390243902439024, (5, 3, 0): 0.23076923076923078, (12, 4, 0): -0.2112676056338028, (14, 6, 0): -0.3090909090909091, (4, 1, 0): -1.0, (14, 7, 1): -0.4117647058823529, (21, 1, 1): 0.3, (19, 6, 0): -0.20833333333333334, (21, 6, 0): -0.16666666666666666, (16, 5, 1): -0.26666666666666666, (16, 1, 1): -0.6666666666666666, (12, 1, 1): -0.5333333333333333, (15, 8, 1): -0.6086956521739131, (12, 8, 1): -0.7142857142857143, (19, 8, 1): -0.04, (10, 4, 0): -0.2903225806451613, (19, 1, 1): -0.2608695652173913, (18, 5, 1): 0.0, (19, 5, 1): 0.23076923076923078, (13, 5, 1): -0.29411764705882354, (21, 7, 1): 0.41304347826086957, (13, 2, 0): -0.27692307692307694, (18, 2, 1): -0.4230769230769231, (16, 2, 1): -0.5, (7, 9, 0): -0.6842105263157895, (21, 2, 1): 0.20512820512820512, (14, 10, 1): -0.8305084745762712, (10, 9, 0): -0.4523809523809524, (12, 7, 1): -0.6, (6, 3, 0): -0.06666666666666667, (14, 6, 1): -0.42857142857142855, (16, 3, 1): -0.2857142857142857, (16, 6, 0): -0.5272727272727272, (16, 4, 1): -0.5, (12, 8, 0): -0.64, (7, 8, 0): -0.3157894736842105, (19, 8, 0): -0.3275862068965517, (8, 7, 0): -0.3333333333333333, (21, 8, 0): -0.3333333333333333, (7, 3, 0): -0.2, (5, 2, 0): 0.6, (18, 10, 1): -0.676923076923077, (10, 6, 0): -0.275, (21, 3, 1): 0.1951219512195122, (19, 3, 1): -0.08, (6, 8, 0): -0.5, (7, 1, 0): -0.7857142857142857, (12, 4, 1): -0.6, (15, 2, 1): -0.5294117647058824, (11, 7, 0): -0.2127659574468085, (16, 7, 1): -0.6470588235294118, (19, 7, 1): 0.1, (14, 9, 1): -0.5238095238095238, (13, 6, 1): -0.26666666666666666, (19, 4, 1): 0.0, (8, 5, 0): -0.4074074074074074, (8, 2, 0): -0.34782608695652173, (18, 4, 1): 0.2777777777777778, (21, 4, 0): -0.07407407407407407, (9, 5, 0): -0.12121212121212122, (21, 7, 0): 0.2, (6, 7, 0): -0.2631578947368421, (8, 1, 0): -0.72, (21, 5, 0): -0.16, (12, 3, 1): -0.07692307692307693, (5, 5, 0): 0.1111111111111111, (20, 8, 1): 0.125, (16, 8, 1): -0.7142857142857143, (15, 1, 1): -0.6666666666666666, (14, 2, 1): -0.2631578947368421, (13, 4, 1): -0.375, (10, 3, 0): -0.13513513513513514, (6, 10, 0): -0.5833333333333334, (18, 3, 1): -0.08, (15, 9, 1): 0.2, (13, 9, 1): -0.5, (21, 6, 1): 0.30952380952380953, (20, 6, 1): 0.047619047619047616, (14, 4, 1): -0.38461538461538464, (21, 2, 0): 0.2727272727272727, (7, 6, 0): -0.47619047619047616, (16, 9, 1): -0.8571428571428571, (13, 8, 1): -0.8181818181818182, (13, 1, 1): -0.7894736842105263, (18, 7, 1): -0.09090909090909091, (6, 1, 0): -0.7777777777777778, (15, 6, 1): -0.041666666666666664, (16, 6, 1): 0.09090909090909091, (17, 1, 1): -0.8636363636363636, (20, 1, 1): -0.43478260869565216, (9, 3, 0): -0.22580645161290322, (21, 9, 0): 0.16666666666666666, (4, 5, 0): 0.0, (7, 4, 0): -0.17647058823529413, (14, 1, 1): -0.5882352941176471, (5, 6, 0): 0.0, (12, 6, 1): 0.0, (14, 5, 1): -0.14285714285714285, (17, 6, 1): -0.375, (4, 6, 0): 0.1111111111111111, (19, 6, 1): -0.05, (12, 10, 1): -0.8181818181818182, (18, 9, 1): 0.1, (5, 4, 0): -0.25, (4, 7, 0): -0.3333333333333333, (4, 10, 0): 0.0, (4, 9, 0): -1.0, (12, 5, 1): -0.09090909090909091, (6, 2, 0): -0.2, (5, 7, 0): -0.6, (5, 9, 0): -1.0, (4, 8, 0): -0.2, (12, 9, 1): -0.75, (4, 2, 0): -0.6666666666666666, (18, 1, 1): -0.5, (4, 4, 0): 0.0, (5, 1, 0): -0.6})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Simple Blackjack environment\n",
    "class BlackjackEnv:\n",
    "    def __init__(self):\n",
    "        self.deck = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10] * 4\n",
    "        self.player = []\n",
    "        self.dealer = []\n",
    "    \n",
    "    def draw_card(self):\n",
    "        \"\"\"Draw a random card from the deck.\"\"\"\n",
    "        return random.choice(self.deck)\n",
    "    \n",
    "    def hand_value(self, hand):\n",
    "        \"\"\"Calculate the value of a hand.\"\"\"\n",
    "        value = sum(hand)\n",
    "        # Adjust for usable ace\n",
    "        if 1 in hand and value + 10 <= 21:\n",
    "            return value + 10\n",
    "        return value\n",
    "    \n",
    "    def is_bust(self, hand):\n",
    "        \"\"\"Check if hand value is over 21 (bust).\"\"\"\n",
    "        return self.hand_value(hand) > 21\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the game and deal initial cards to player and dealer.\"\"\"\n",
    "        self.player = [self.draw_card(), self.draw_card()]\n",
    "        self.dealer = [self.draw_card(), self.draw_card()]\n",
    "        return self._get_observation()\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action: hit or stick.\"\"\"\n",
    "        if action == 'hit':\n",
    "            self.player.append(self.draw_card())\n",
    "            if self.is_bust(self.player):\n",
    "                return self._get_observation(), -1, True  # Player busts\n",
    "            else:\n",
    "                return self._get_observation(), 0, False  # Continue game\n",
    "        elif action == 'stick':\n",
    "            while self.hand_value(self.dealer) < 17:\n",
    "                self.dealer.append(self.draw_card())\n",
    "            if self.is_bust(self.dealer):\n",
    "                return self._get_observation(), 1, True  # Dealer busts\n",
    "            elif self.hand_value(self.dealer) > self.hand_value(self.player):\n",
    "                return self._get_observation(), -1, True  # Dealer wins\n",
    "            elif self.hand_value(self.dealer) < self.hand_value(self.player):\n",
    "                return self._get_observation(), 1, True  # Player wins\n",
    "            else:\n",
    "                return self._get_observation(), 0, True  # Draw\n",
    "    \n",
    "    def _get_observation(self):\n",
    "        \"\"\"Return the current game state.\"\"\"\n",
    "        return (self.hand_value(self.player), self.dealer[0], 1 if 1 in self.player else 0)  # (Player total, Dealer card, Usable ace)\n",
    "\n",
    "# Monte Carlo Prediction for Blackjack\n",
    "def mc_blackjack_prediction(episodes=10000, gamma=1.0):\n",
    "    # Initialize environment\n",
    "    env = BlackjackEnv()\n",
    "    V = defaultdict(float)  # State-value function\n",
    "    returns = defaultdict(list)  # Store returns for each state\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        episode = []\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        # Generate an episode\n",
    "        while not done:\n",
    "            action = random.choice(['hit', 'stick'])  # Random policy\n",
    "            next_state, reward, done = env.step(action)\n",
    "            episode.append((state, action, reward))\n",
    "            state = next_state\n",
    "        \n",
    "        # Calculate returns and update V for first-visit\n",
    "        G = 0\n",
    "        visited_states = set()\n",
    "        for state, action, reward in reversed(episode):\n",
    "            G = gamma * G + reward\n",
    "            if state not in visited_states:\n",
    "                returns[state].append(G)\n",
    "                V[state] = np.mean(returns[state])  # First-visit update\n",
    "                visited_states.add(state)\n",
    "\n",
    "    return V\n",
    "\n",
    "# Run Monte Carlo prediction\n",
    "V = mc_blackjack_prediction()\n",
    "print(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Policy:\n",
      "State (0, 0): Best action -> down\n",
      "State (0, 1): Best action -> down\n",
      "State (1, 1): Best action -> right\n",
      "State (0, 2): Best action -> right\n",
      "State (0, 3): Best action -> down\n",
      "State (1, 3): Best action -> down\n",
      "State (1, 2): Best action -> down\n",
      "State (2, 3): Best action -> down\n",
      "State (2, 2): Best action -> right\n",
      "State (1, 0): Best action -> right\n",
      "State (2, 0): Best action -> right\n",
      "State (2, 1): Best action -> down\n",
      "State (3, 0): Best action -> up\n",
      "State (3, 1): Best action -> right\n",
      "State (3, 2): Best action -> right\n",
      "\n",
      "Learned Q-Values:\n",
      "State (0, 0): {'up': -0.36918650060780034, 'down': 0.16357620687307062, 'left': -0.20283849999999978, 'right': -0.7047549991805321}\n",
      "State (0, 1): {'up': -0.9999999987859735, 'down': -0.4751199976788043, 'left': -0.9999999999999994, 'right': -0.9999999999999994}\n",
      "State (1, 1): {'up': -0.6063399999999995, 'down': -0.27099999999999963, 'left': -0.2460809875112374, 'right': 0.44725180993927144}\n",
      "State (0, 2): {'up': -0.8764653207432103, 'down': -0.9999999999999994, 'left': -0.9999999999999994, 'right': 0.09258018877768526}\n",
      "State (0, 3): {'up': -0.5139999995296611, 'down': 0.324358329993009, 'left': -0.8471121030513292, 'right': -0.9999999993650426}\n",
      "State (1, 3): {'up': -0.9999444667132742, 'down': 0.7026363636363638, 'left': -0.9999999999999994, 'right': -0.9999999999999994}\n",
      "State (1, 2): {'up': -0.019766197167222156, 'down': 0.612299178644764, 'left': -0.02136123999999977, 'right': 0.35000000000000014}\n",
      "State (2, 3): {'up': 0.35000000000000014, 'down': 1.0, 'left': 0.6200000000000001, 'right': 0.8}\n",
      "State (2, 2): {'up': 0.022031545098999922, 'down': 0.3898832215384363, 'left': 0.322339023666543, 'right': 0.7967730569948187}\n",
      "State (1, 0): {'up': -0.4095087831287398, 'down': -0.14319992489801886, 'left': -0.08270174527870382, 'right': 0.29965959325751784}\n",
      "State (2, 0): {'up': -0.9999999999999994, 'down': -0.9999999999999994, 'left': -0.9999907386128687, 'right': 0.047200297599913066}\n",
      "State (2, 1): {'up': -0.7675382960557423, 'down': 0.4198882414950351, 'left': -0.9999771323774542, 'right': -0.54246415090078}\n",
      "State (3, 0): {'up': -0.969096845617367, 'down': -0.9999992147981445, 'left': -0.999996567692534, 'right': -0.9998119077826026}\n",
      "State (3, 1): {'up': -0.9749683641170179, 'down': -0.18994446671327447, 'left': -0.9999150051613361, 'right': 0.5959275732826368}\n",
      "State (3, 2): {'up': -0.8564204024616294, 'down': -0.9982809910885656, 'left': -0.9970888433141385, 'right': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class GridWorldEnv:\n",
    "    def __init__(self, grid_size=(4, 4), goal_state=(3, 3)):\n",
    "        self.grid_size = grid_size\n",
    "        self.goal_state = goal_state\n",
    "        self.actions = ['up', 'down', 'left', 'right']\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the environment and return the starting state.\"\"\"\n",
    "        self.state = (0, 0)  # Start at top-left corner\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take a step in the environment.\"\"\"\n",
    "        row, col = self.state\n",
    "\n",
    "        if action == 'up':\n",
    "            next_state = (max(row - 1, 0), col)\n",
    "        elif action == 'down':\n",
    "            next_state = (min(row + 1, self.grid_size[0] - 1), col)\n",
    "        elif action == 'left':\n",
    "            next_state = (row, max(col - 1, 0))\n",
    "        elif action == 'right':\n",
    "            next_state = (row, min(col + 1, self.grid_size[1] - 1))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown action: {action}\")\n",
    "\n",
    "        self.state = next_state\n",
    "\n",
    "        if self.state == self.goal_state:\n",
    "            reward = 1  # Reward for reaching the goal\n",
    "            done = True\n",
    "        else:\n",
    "            reward = -0.1  # Small penalty for each step\n",
    "            done = False\n",
    "\n",
    "        return next_state, reward, done\n",
    "\n",
    "    def sample_action(self):\n",
    "        \"\"\"Randomly sample an action.\"\"\"\n",
    "        return random.choice(self.actions)\n",
    "\n",
    "def epsilon_greedy_action(state, Q, epsilon, actions):\n",
    "    \"\"\"Choose an action using epsilon-greedy.\"\"\"\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(actions)  # Explore: random action\n",
    "    else:\n",
    "        return max(Q[state], key=Q[state].get)  # Exploit: best action based on Q-values\n",
    "\n",
    "def generate_episode(env, Q, epsilon):\n",
    "    \"\"\"Generates an episode using epsilon-greedy policy.\"\"\"\n",
    "    episode = []\n",
    "    state = env.reset()\n",
    "    while True:\n",
    "        action = epsilon_greedy_action(state, Q, epsilon, env.actions)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        episode.append((state, action, reward))\n",
    "        state = next_state\n",
    "        if done:\n",
    "            break\n",
    "    return episode\n",
    "\n",
    "def monte_carlo_control(env, episodes=1000, gamma=0.9, epsilon=0.1):\n",
    "    \"\"\"Performs Monte Carlo control with epsilon-greedy policy.\"\"\"\n",
    "    Q = defaultdict(lambda: {a: 0.0 for a in env.actions})  # Initialize Q-values\n",
    "    returns = defaultdict(list)  # To store all returns for state-action pairs\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        # Generate an episode\n",
    "        episode = generate_episode(env, Q, epsilon)\n",
    "        G = 0  # Initialize return\n",
    "\n",
    "        # Loop backward over the episode\n",
    "        for t in range(len(episode)-1, -1, -1):\n",
    "            state, action, reward = episode[t]\n",
    "            G = reward + gamma * G  # Calculate cumulative return\n",
    "\n",
    "            # First visit Monte Carlo: check if state-action pair was visited earlier in episode\n",
    "            if (state, action) not in [(x[0], x[1]) for x in episode[:t]]:\n",
    "                returns[(state, action)].append(G)  # Store return\n",
    "                Q[state][action] = np.mean(returns[(state, action)])  # Update Q-value\n",
    "\n",
    "        # Optionally decrease epsilon over time (to reduce exploration)\n",
    "        epsilon = max(epsilon * 0.99, 0.01)  # Decrease epsilon\n",
    "\n",
    "    # Extract the optimal policy from Q-values\n",
    "    policy = {state: max(Q[state], key=Q[state].get) for state in Q}\n",
    "    return Q, policy\n",
    "\n",
    "# Initialize environment and run Monte Carlo with epsilon-greedy\n",
    "env = GridWorldEnv()\n",
    "Q, optimal_policy = monte_carlo_control(env)\n",
    "\n",
    "# Display the optimal policy\n",
    "print(\"Optimal Policy:\")\n",
    "for state, action in optimal_policy.items():\n",
    "    print(f\"State {state}: Best action -> {action}\")\n",
    "\n",
    "# Display the learned Q-values\n",
    "print(\"\\nLearned Q-Values:\")\n",
    "for state, actions in Q.items():\n",
    "    print(f\"State {state}: {actions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
